{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-09T19:29:08.312771200Z",
     "start_time": "2024-09-09T19:29:02.113341500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "● Download a dataset for object detection tasks\n",
    "● Preprocess the dataset:\n",
    "● Split the dataset into training, validation, and test sets. -- only splitting in train and test\n",
    "● Prepare annotations for object bounding boxes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Directories\n",
    "# TODO : make a validation set here as well\n",
    "\n",
    "# unzip downloaded data from kaggle link into fruit_dataset folder\n",
    "train_dir = r'C:\\Users\\praka\\Acads\\M_Tech\\bits\\Sem 3\\CV\\asmt_labs\\asmt2\\fruit_dataset\\train_zip\\train'\n",
    "test_dir = r'C:\\Users\\praka\\Acads\\M_Tech\\bits\\Sem 3\\CV\\asmt_labs\\asmt2\\fruit_dataset\\test_zip\\test'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T19:27:09.432092200Z",
     "start_time": "2024-09-09T19:27:09.409497400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def extract_annotations(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    boxes = []\n",
    "    filename = root.find('filename').text\n",
    "    width = int(root.find('size/width').text)\n",
    "    height = int(root.find('size/height').text)\n",
    "\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        xmin = int(obj.find('bndbox/xmin').text)\n",
    "        ymin = int(obj.find('bndbox/ymin').text)\n",
    "        xmax = int(obj.find('bndbox/xmax').text)\n",
    "        ymax = int(obj.find('bndbox/ymax').text)\n",
    "\n",
    "        boxes.append([filename, width, height, label, xmin, ymin, xmax, ymax])\n",
    "\n",
    "    return boxes\n",
    "\n",
    "# Function to read all annotations from a directory\n",
    "def parse_annotations_from_directory(directory):\n",
    "    annotations = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".xml\"):\n",
    "            xml_file = os.path.join(directory, file)\n",
    "            annotations.extend(extract_annotations(xml_file))\n",
    "    return annotations\n",
    "\n",
    "train_annotations = parse_annotations_from_directory(train_dir)\n",
    "test_annotations = parse_annotations_from_directory(test_dir)\n",
    "\n",
    "# Convert to pandas DataFrame for easy manipulation\n",
    "columns = ['filename', 'width', 'height', 'label', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "train_df = pd.DataFrame(train_annotations, columns=columns)\n",
    "test_df = pd.DataFrame(test_annotations, columns=columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T19:31:40.103868Z",
     "start_time": "2024-09-09T19:31:40.012786400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       filename  width  height  label  xmin  ymin  xmax  ymax\n0   apple_1.jpg      0       0  apple     8    15   331   349\n1  apple_10.jpg   1500    1500  apple    56    99  1413  1419\n2  apple_11.jpg    652     436  apple   213    33   459   258\n3  apple_11.jpg    652     436  apple     1    30   188   280\n4  apple_11.jpg    652     436  apple   116     5   337   220",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>label</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>apple_1.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>apple</td>\n      <td>8</td>\n      <td>15</td>\n      <td>331</td>\n      <td>349</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>apple_10.jpg</td>\n      <td>1500</td>\n      <td>1500</td>\n      <td>apple</td>\n      <td>56</td>\n      <td>99</td>\n      <td>1413</td>\n      <td>1419</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>apple_11.jpg</td>\n      <td>652</td>\n      <td>436</td>\n      <td>apple</td>\n      <td>213</td>\n      <td>33</td>\n      <td>459</td>\n      <td>258</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>apple_11.jpg</td>\n      <td>652</td>\n      <td>436</td>\n      <td>apple</td>\n      <td>1</td>\n      <td>30</td>\n      <td>188</td>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>apple_11.jpg</td>\n      <td>652</td>\n      <td>436</td>\n      <td>apple</td>\n      <td>116</td>\n      <td>5</td>\n      <td>337</td>\n      <td>220</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T19:55:30.859404700Z",
     "start_time": "2024-09-09T19:55:30.828611500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "((465, 8), (117, 8))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T19:40:19.822106800Z",
     "start_time": "2024-09-09T19:40:19.802615200Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Build Model: 4 Marks\n",
    "● Choose a pre-trained object detection model (e.g., SSD, Faster R-CNN, YOLO).\n",
    "● Load the pre-trained model weights.\n",
    "● Modify the model architecture if necessary (e.g., for transfer learning). -- not modifying weights for now\n",
    "● Set up the model for training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasterRCNN(\n",
      "  (transform): GeneralizedRCNNTransform(\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "  )\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0-3): 4 x Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True, weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T19:41:53.655956200Z",
     "start_time": "2024-09-09T19:41:53.062149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "num_classes = 5  # Assuming background + 1 fruit class (apple, banana, orange, mixed)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torch.nn.Linear(in_features, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T19:46:41.292165700Z",
     "start_time": "2024-09-09T19:46:41.266001100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class FruitDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transforms=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        # Create a mapping of class names to integers\n",
    "        self.class_to_index = {'apple': 1, 'banana': 2, 'orange': 3, 'mixed': 4}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image file\n",
    "        img_name = self.df.iloc[idx]['filename']\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Get bounding boxes\n",
    "        xmin = self.df.iloc[idx]['xmin']\n",
    "        ymin = self.df.iloc[idx]['ymin']\n",
    "        xmax = self.df.iloc[idx]['xmax']\n",
    "        ymax = self.df.iloc[idx]['ymax']\n",
    "        boxes = [[xmin, ymin, xmax, ymax]]\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        # Get labels\n",
    "        class_name = self.df.iloc[idx]['label']  # 'label' column contains the fruit names\n",
    "        label = self.class_to_index.get(class_name, 0)  # Default to 0 if class_name not found\n",
    "        labels = torch.as_tensor([label], dtype=torch.int64)\n",
    "\n",
    "        # Create target dict\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Image transformations\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Initialize Dataset and DataLoader\n",
    "train_dataset = FruitDataset(train_df, train_dir, transforms=transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "# Making model available for training:\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T19:59:05.390948600Z",
     "start_time": "2024-09-09T19:59:05.374780500Z"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Training: 3 Marks\n",
    "● Define training parameters such as batch size, learning rate, and number of\n",
    "epochs.\n",
    "● Train the object detection model using the training dataset.\n",
    "● Monitor the training process and visualize training metrics (e.g., loss, accuracy)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-09T20:01:47.296648900Z",
     "start_time": "2024-09-09T20:01:47.236370200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
